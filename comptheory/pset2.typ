#import "template.typ": *
#show: template.with(
  title: "PSET 2",
  subtitle: "18.404",
  pset: true,
)

= Problem 1

Recall that the CFL Pumping Lemma specifies that for a CFL $bold(L)$, there is a string of length at least $p$ in the language such that:

+ $u v^i x y^i z$ is in $bold(L)$ for all $i >= 0$
+ $v y != epsilon$
+ $|v x y| <= p$

== (a)

Let us apply the Pumping Lemma to the string $s = 1^p 3^p 2^p 4^p$

Because $|v x y| <= p$, this means that no matter how we choose the slice, we will never be able to get both a $(1, 2)$ or $(3, 4)$ in the same $v x y$ slice. Therefore, since $v y != epsilon$, it must be the case that when we pump the string up or down, there will be a pair, perhaps even two, that become uneven. Thus this language cannot be context free.

== (b)

Suppose we have the languages:

$
L_1 = {w | w "has an equal number of" 1"s and" 2"s"}\
L_3 = {w | w "has an equal number of" 3"s and" 4"s"}
$

Let us show that these languages of dual equality are context free. The following grammar generates a language that recognizes any string with an equal number of $1$s and $0$s:

$
S -> S S | 1 S 0 | 0 S 1 | epsilon
$

It is immediately evident why this grammar generates strings that have an equal number of $1$s and $0$s. However, we also need to show that this language generates *all* strings that are a part of the language of equal $1$s and $0$s. We can do this by induction. The base case is trivial with the empty string. For our inductive step, assume that we have string of length $2n$ for $n >= 1$

WLOG assume that the first character is a $1$. We must now consider two cases:

+ If the last character is a $0$, then we can write the string as $1 s 0$, where we know the middle $s$ can be generated by induction.
+ If the last character is a $1$, then it must be the case that we can split the string into two pieces such that each of them have an equal number of $1$s and $0$s. This is because we start out with one too many $1$s, but then by the $2n - 1$ character, are lacking a $1$. Because each character we read can only change this difference by 1, there must have been a point in the middle where we had an equal number of $1$s and $0$s, similar to how the intermediate value theorem works in calculus. Thus it can be represented by the string $s_1 s_2$ where neither $s$ is empty, which we know can be generated from induction.

Thus we show how using the grammar specified above, we can generate all strings that have an equal number of $1$s and $0$s.

We now know that these languages are CFLs. It should then be the case that $L_1 sect L_3 = C$. However, we have just shown that $C$ is not context free, which means that CFLs can't be closed under the intersection operator.

Additionally, if we know that CFLs aren't closed under the intersection operator, it follows from DeMorgan's Law that they can't be closed under the complement operator as well.

== (c)

Note that $C$ is a language that only contains even length strings since the matching nature means we will never have an odd length. Thus $C$ is entirely contained within the regular language $(Sigma Sigma)^*$ - that is, $C union (Sigma Sigma)^* = (Sigma Sigma)^*$

The latter is a regular expression, which we know from lecture is less powerful, and can be simulated by a CFL. Thus the resulting union is a CFL.

== (d)

Contrary to above, the right hand side of the union contains a regular expression of all odd length strings. These two languages are completely disjoint from one another. However, it might be the case that the union allows for new possibilities that make the resulting language a CFL. However, this is not the case, and we can show it with the exact same Pumping Lemma argument as in *(a)*

With the presence of the union, the Pumping Lemma might be saved if we can pump the string $1^p 3^p 2^p 4^p$ to be in the language $Sigma (Sigma Sigma)^*$ (we have already shown that it can't pump to $C$). Unfortunately, this cannot be the case. Assume that $|v y|$ is odd. If we pump the string an odd number of times, we are okay because that falls within the $Sigma (Sigma Sigma)^*$ language. However, if we pump the string an even number of times, we will have an even length string. The only part of this new language that could accept an even length string is the original language $C$, which cannot be the case since we have shown that $C$ is not context free. An even simpler argument can be made for even length $|v y|$ since that will always pump up or down to an even length string. In order for the Pumping Lemma to work, we must be able to find a split that works for all $i$ on the pump, which is not the case.

Thus the resulting union cannot be a CFL.

= Problem 2

== (a)

#twocola(
  bimg("imgs/p3p2.png", width: 80%),
  [
    The two trees on the left show two different parse trees for the grammar that produces the string:

    ```
    if condition then
      if condition then a := 1 else a := 1
    ```

    The problem arises in the grammar when trying to tell which `if` the `else` belongs to. This is the realized problem that comes from the ambiguity in the grammar.
  ]
)

== (b)

```
STMT       => <ASSIGN>
            | <IFTHEN>
IFTHEN     => if condition then <NEXT>
NEXT       => <IFTHEN>
            | <ASSIGNNEXT>
ASSIGNNEXT => <ASSIGN>
            | <ASSIGN> else <IFTHEN>
ASSIGN     => a := 1
```

There are several observations which make this new grammar possible. First, note that every `else` must be preceded by `a := 1`. Then also note that The only thing that can come after an `if` block is another `if` block or an `assign`. Lastly, note that the generated string will always terminate on `a := 1`. With these in mind, we can generate this new grammar which is gives the exact same language.

To make the reasoning more explicit, I have split some steps up into smaller sub-steps in the language. The idea for why this grammar is not ambiguous is that any expansion always has a terminal to the left, then variables to the right. Thus, the parse tree will always grow in the same way, with a heavy right tree that keeps adding terminals to the right end of the generated string. Thus it becomes impossible to have the same string come from different parse trees because there is only one way to generate a string from left to right with the grammar.

= Problem 3

== Forwards Direction

If a language is recognized by a deterministic queue automaton, let us show that it is Turing-recognizable.

To show this, we can simply simulate the queue automaton on a two-tape TM, which we showed in lecture to be equivalent to any other TM. The first tape will contain the input tape, and the second tape will simulate the queue. We will additionally add a special character to the tape alphabet $epsilon$ that marks the beginning of the queue. The second tape will simply start with a singular $epsilon$

- When a character is pushed, the head of the tape moves to the right until it finds a blank slot (not $epsilon$!), after which it then writes the character to be pushed.
- When a character is popped, the head of the tape moves to the left to the first $epsilon$ it finds, then replaces the first character after $epsilon$ with $epsilon$.

We will then end up with a tape that has leading $epsilon$ as we pop more and more values off, and the back of the queue will continually move to the right. This is perfectly fine in a TM as the tape goes on infinitely towards the right. Thus we provide a way to simulate a deterministic queue automaton on a TM with two tapes, meaning that it can be simulated on TMs in general.

== Backwards Direction

If a language is Turing-recognizable, let us show that it is recognized by a deterministic queue automaton.

Our objective will be to show that we can simulate the tape of a TM with a queue. We can do this by showing how to do two operations on a queue where we imagine the front (where we pop from) to be at the left:

+ Optionally change a character and rotate to the right
+ Optionally change a character and rotate to the left

We imagine the queue can trivially read the character at the head. The head of the queue will take place as the pointer location for a TM. With these operations, we can simulate all the necessarily functionality that a TM allows us to do. Let us now show that we can perform both of these rotations and changes. Note that similar to above, we will have a special symbol $epsilon$ that marks the beginning of the tape.

== (Change) and Rotate Right

Imagine our queue looks like:

$ a b c epsilon $

This means that our tape is $a b c$, with the head of the tape currently at $a$. To simulate rotating to the left, all we need to do is pop the head of the queue and push either it or another symbol to the back, depending on whether we want to rewrite or simply move without changing the current value. Let's say that we wanted to rewrite a new value $d$ to the current location and rotate left. We would then have:

$ b c epsilon d $

We can see that functionally, we have written a new value (which could also have been kept as $a$), and moved our tape head to the right so we are now at $b$

== (Change) and Rotate Left

Because this direction goes against the natural flow of the queue, there is a bit more work that needs to go on in order for the rotation to happen correctly. Again suppose that our tape simulation looks like the following:

$ a b c epsilon $

Let's say we want to rewrite the current value to $d$ and rotate left. It's tempting to say that we should just push the new value $d$ to the queue, then repeatedly rotate until $d$ is at the head of the queue. The problem is that there is no way for us to know where the new value is, and therefore where to stop ($d$). Instead, we need to keep track of where our current location on the tape is. We will do this by adding a new special symbol $epsilon'$ that marks the current location of the tape head. We will then have:

$ b c epsilon epsilon' d $

Now we will (in the state automata), enter a special state that says we are rotating to the left, which will keep popping and pushing the same value until we reach the special $epsilon'$, at which point we will stop and remove the $epsilon'$ from the queue. We will then have:

$ epsilon d b c $

We now possess the ability to rotate both ways, meaning we can simulate a TM! There is one slightly special case that I have not covered, which is the possibility that we wish to write to the right of the tape in a location that we have not written in. For this case, after we rotate right, if we notice the $epsilon$, then if the next instruction for the tape is to write then move to the right again, we can simply push the value, then not cycle, since we are already at the correct head location of $epsilon$. Otherwise, if we are moving to the left, we can simulate the same process described above to simulate the TM.

= Problem 4

== Forwards Direction

If there exists a decidable language, let us show that there exists some enumerator that enumerates the language in string order.

To create such an enumerator, we can simulate running the decider on a TM for all strings of the alphabet in string order. If the decider accepts, we output the string. Because we have a decider, the TM will never get stuck on a particular string, and thus, if we run each of the inputs sequentially and not in parallel, we produce an enumerator that enumerates the language in string order.

== Backwards Direction

If there exists an enumerator that enumerates the language in string order, let us show that there exists a decider for that language.

To create such a decider, for string $s$, we can run the enumerator sequentially on a TM until we reach $|s|$. At each point, compare the enumerated string to $s$. If we find a match, accept, and otherwise reject since we know the enumerator goes in order. Because we have a fixed length to which we search, we know the decider will terminate in a finite number of steps, and is thus, a decider and not a recognizer.


= Problem 5

== Forwards Direction

If there exists a Turing-recognizable language $C$, let us show that there exists a decidable language $D$ as specified.

We want to encode some information in the second part of $angle.l x, y angle.r$ such that we can confirm that $x in C$ without looping. We could do this by making a decider that takes the following form:

$ D = {angle.l x, y angle.r | M "accepts" x "with steps" y} $

The implication here is that $|y|$ is equal to the length of the steps that the TM takes to accept $x$. Because we can prescribe a finite length to each string, this $D$ is clearly decidable, and thus we have shown that the decidable counterpart to $C$ exists.

== Backwards Direction

If there exists a decidable language $D$ as specified, let us show that there exists a Turing-recognizable language $C$ for it.

This direction is much easier - given that the decider exists, and that $C$ does not have to be a decider itself, to check any input string $S$, we can take all strings in order and check the concatenation with $S$ with the decider $D$. If we ever find a match that is in $D$, then we accept, otherwise we reject by looping which is allowed in a recognizer.


= Problem 6

In the emptiness proof for DFAs, we did a graph search from the start state to explore all reachable states. We will do a similar procedure here.

We want to make a decider $D$ such that it takes in a PDA and confirms that it uses the stack to push at some point.

$D$ = "On input $P$ where $P$ is a PDA
+ *Mark* start state
+ *Repeat* until no new states are marked:
  - *Mark* any state $q$ if there is a transition from a marked state to $q$
  - *Specially Mark* any state $q$ if it fulfills the above but also comes from a transition that pushes to the stack
+ _Accept_ if there is a *specially* marked state\
 _Reject_ otherwise"

Because there are a finite number of states $Q$ in the PDA, this graph traversal will terminate in a finite number of steps since we can't repeatedly mark nodes. Thus we have created a decider for this language $"PUSHER"$, and $"PUSHER"$ is decidable.
